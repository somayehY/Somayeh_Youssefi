{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eedd5a01",
   "metadata": {},
   "source": [
    "## Table of content\n",
    "\n",
    "* [1. Imports](#imports)\n",
    "* [2. Open File](#open)\n",
    "* [3. Find Board Books](#board)\n",
    "* [4. Content Based Recommendation System: based on book description](#recom_desc)\n",
    "    * [4.1. Clean and Lemmatize Book Description](#clean_desc)\n",
    "    * [4.2 Recommendation System: based on book description](#function)\n",
    "* [5. Content Based Recommendation System based on reviews](#reviews)\n",
    "    * [5.1 Clean and Lemmatize Reviews](#clean_rev)\n",
    "    * [5.2 Recommendation System: based on book reviews](#function_rev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e475d",
   "metadata": {},
   "source": [
    "In this notebook we built two recommendation systems. The first is for toddler books and the second is for older kids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b29a024",
   "metadata": {},
   "source": [
    "## 1. Imports <a class='anchor' id='imports'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "2e578431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\somfl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\somfl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from matplotlib import pyplot\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00982cb9",
   "metadata": {},
   "source": [
    "## 2. Open File <a class='anchor' id='open'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "ae32e885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>authors</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>image_url</th>\n",
       "      <th>url</th>\n",
       "      <th>similar_books</th>\n",
       "      <th>authors_names</th>\n",
       "      <th>genres</th>\n",
       "      <th>positive_review</th>\n",
       "      <th>negative_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>287141</td>\n",
       "      <td>1599150603</td>\n",
       "      <td>The Aeneid for Boys and Girls</td>\n",
       "      <td>Relates in vigorous prose the tale of Aeneas, ...</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{'author_id': '3041852', 'role': ''}]</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.13</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "      <td>https://www.goodreads.com/book/show/287141.The...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Alfred J. Church</td>\n",
       "      <td>{'history, historical fiction, biography': 9, ...</td>\n",
       "      <td>Once again, my kids loved this book about anci...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6066812</td>\n",
       "      <td>1934876569</td>\n",
       "      <td>All's Fairy in Love and War (Avalon: Web of Ma...</td>\n",
       "      <td>To Kara's astonishment, she discovers that a p...</td>\n",
       "      <td>216.0</td>\n",
       "      <td>[{'author_id': '19158', 'role': ''}]</td>\n",
       "      <td>98.0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>https://images.gr-assets.com/books/1316637798m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/6066812-al...</td>\n",
       "      <td>['948696', '439885', '274955', '12978730', '37...</td>\n",
       "      <td>['Rachel Roberts']</td>\n",
       "      <td>{'fantasy, paranormal': 32, 'young-adult': 8, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This was a really cute book, though to be hone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89378</td>\n",
       "      <td>0590417010</td>\n",
       "      <td>Dog Heaven</td>\n",
       "      <td>In Newbery Medalist Cynthia Rylant's classic b...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[{'author_id': '5411', 'role': ''}]</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>4.43</td>\n",
       "      <td>https://images.gr-assets.com/books/1360057676m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/89378.Dog_...</td>\n",
       "      <td>['834493', '452189', '140185', '1897316', '218...</td>\n",
       "      <td>['Cynthia Rylant']</td>\n",
       "      <td>{'children': 109, 'fiction': 13, 'non-fiction'...</td>\n",
       "      <td>Really cute, sweet, and charming.,This beautif...</td>\n",
       "      <td>I probably would have liked this book more if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1698376</td>\n",
       "      <td>1416904999</td>\n",
       "      <td>What Do You Do?</td>\n",
       "      <td>WHAT DO YOU DO?\\nA hen lays eggs...\\nA cow giv...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>[{'author_id': '169159', 'role': ''}]</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.57</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "      <td>https://www.goodreads.com/book/show/1698376.Wh...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Mandy Stanley']</td>\n",
       "      <td>{'children': 6}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Colourful. Fun to read. My daughter enjoys thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3631900</td>\n",
       "      <td>0884482987</td>\n",
       "      <td>Amadi's Snowman: A Story of Reading</td>\n",
       "      <td>When Amadi disobeys his mother and runs off to...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>[{'author_id': '1540277', 'role': ''}, {'autho...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>https://images.gr-assets.com/books/1300370678m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/3631900-am...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Katia Novet Saint-Lot', 'Dimitrea Tokunbo']</td>\n",
       "      <td>{'fiction': 6, 'children': 8, 'young-adult': 1}</td>\n",
       "      <td>My nine-year-old son and I enjoyed this book a...</td>\n",
       "      <td>This is an enjoyable book, and Amadi is an eng...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id        isbn                                              title  \\\n",
       "0   287141  1599150603                      The Aeneid for Boys and Girls   \n",
       "1  6066812  1934876569  All's Fairy in Love and War (Avalon: Web of Ma...   \n",
       "2    89378  0590417010                                         Dog Heaven   \n",
       "3  1698376  1416904999                                    What Do You Do?   \n",
       "4  3631900  0884482987                Amadi's Snowman: A Story of Reading   \n",
       "\n",
       "                                         description  num_pages  \\\n",
       "0  Relates in vigorous prose the tale of Aeneas, ...      162.0   \n",
       "1  To Kara's astonishment, she discovers that a p...      216.0   \n",
       "2  In Newbery Medalist Cynthia Rylant's classic b...       40.0   \n",
       "3  WHAT DO YOU DO?\\nA hen lays eggs...\\nA cow giv...       24.0   \n",
       "4  When Amadi disobeys his mother and runs off to...       32.0   \n",
       "\n",
       "                                             authors  ratings_count  \\\n",
       "0             [{'author_id': '3041852', 'role': ''}]           46.0   \n",
       "1               [{'author_id': '19158', 'role': ''}]           98.0   \n",
       "2                [{'author_id': '5411', 'role': ''}]         1331.0   \n",
       "3              [{'author_id': '169159', 'role': ''}]           23.0   \n",
       "4  [{'author_id': '1540277', 'role': ''}, {'autho...           44.0   \n",
       "\n",
       "   average_rating                                          image_url  \\\n",
       "0            4.13  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
       "1            4.22  https://images.gr-assets.com/books/1316637798m...   \n",
       "2            4.43  https://images.gr-assets.com/books/1360057676m...   \n",
       "3            3.57  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
       "4            3.89  https://images.gr-assets.com/books/1300370678m...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.goodreads.com/book/show/287141.The...   \n",
       "1  https://www.goodreads.com/book/show/6066812-al...   \n",
       "2  https://www.goodreads.com/book/show/89378.Dog_...   \n",
       "3  https://www.goodreads.com/book/show/1698376.Wh...   \n",
       "4  https://www.goodreads.com/book/show/3631900-am...   \n",
       "\n",
       "                                       similar_books  \\\n",
       "0                                                 []   \n",
       "1  ['948696', '439885', '274955', '12978730', '37...   \n",
       "2  ['834493', '452189', '140185', '1897316', '218...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                   authors_names  \\\n",
       "0                               Alfred J. Church   \n",
       "1                             ['Rachel Roberts']   \n",
       "2                             ['Cynthia Rylant']   \n",
       "3                              ['Mandy Stanley']   \n",
       "4  ['Katia Novet Saint-Lot', 'Dimitrea Tokunbo']   \n",
       "\n",
       "                                              genres  \\\n",
       "0  {'history, historical fiction, biography': 9, ...   \n",
       "1  {'fantasy, paranormal': 32, 'young-adult': 8, ...   \n",
       "2  {'children': 109, 'fiction': 13, 'non-fiction'...   \n",
       "3                                    {'children': 6}   \n",
       "4    {'fiction': 6, 'children': 8, 'young-adult': 1}   \n",
       "\n",
       "                                     positive_review  \\\n",
       "0  Once again, my kids loved this book about anci...   \n",
       "1                                                NaN   \n",
       "2  Really cute, sweet, and charming.,This beautif...   \n",
       "3                                                NaN   \n",
       "4  My nine-year-old son and I enjoyed this book a...   \n",
       "\n",
       "                                     negative_review  \n",
       "0                                                NaN  \n",
       "1  This was a really cute book, though to be hone...  \n",
       "2  I probably would have liked this book more if ...  \n",
       "3  Colourful. Fun to read. My daughter enjoys thi...  \n",
       "4  This is an enjoyable book, and Amadi is an eng...  "
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\somfl\\\\Documents\\\\GitHub\\\\Somayeh_Youssefi\\\\Book Recomendation System\\\\data_files\\\\CleanedBooks.csv'\n",
    "df = pd.read_csv(path, sep=',')\n",
    "df.drop(columns='Unnamed: 0', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "477a1748",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['description'], axis=0, inplace = True)\n",
    "df = df.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "aab9d19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_id                0\n",
       "isbn                4542\n",
       "title                  0\n",
       "description            0\n",
       "num_pages              0\n",
       "authors                0\n",
       "ratings_count          0\n",
       "average_rating         0\n",
       "image_url              0\n",
       "url                    0\n",
       "similar_books          0\n",
       "authors_names          0\n",
       "genres                 0\n",
       "positive_review    10638\n",
       "negative_review    22768\n",
       "dtype: int64"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "36fbdff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['title'], keep='first', inplace = True)\n",
    "df = df.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382195dc",
   "metadata": {},
   "source": [
    "## 3. Book Recommendation System for Toddlers <a class='anchor' id='recom_desc'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db06f139",
   "metadata": {},
   "source": [
    "### 3.1.  Find Board Books <a class='anchor' id='board'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "7df32b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many board books we have:\n",
    "board_book_list = []\n",
    "for i in range(len(df)):\n",
    "    text = df.loc[i, 'description'].lower()\n",
    "    if ((re.search('board book', text)) or (re.search('sensory', text)) or (re.search('touch', text)) or (re.search('flap',text))\n",
    "    or (re.search('new reader', text)) or (re.search('teach color', text)) or (re.search('teach numbers', text)) \n",
    "    or (re.search('teach color', text)) or (re.search('infant', text)) or (re.search('toddler', text)) or (re.search('baby', text))\n",
    "    or (re.search('illustration', text) and re.search('toddler', text)) or (re.search('picture', text) and re.search('toddler', text))\n",
    "    or (re.search('illustration', text) and re.search('baby', text)) or (re.search('picture', text) and re.search('toddler', text))\n",
    "       or (re.search('sesame street', text)) or (re.search('dr. seuss', text))):\n",
    "        board_book_list.append(df.loc[i,'book_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "b8bad079",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['book_id'].isin(board_book_list)\n",
    "df_board_book = df[mask]\n",
    "df_board_book = df_board_book.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "b2b17295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4937, 16)"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_board_book.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "1ddd0a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                 0\n",
       "book_id               0\n",
       "isbn                238\n",
       "title                 0\n",
       "description           0\n",
       "num_pages             0\n",
       "authors               0\n",
       "ratings_count         0\n",
       "average_rating        0\n",
       "image_url             0\n",
       "url                   0\n",
       "similar_books         0\n",
       "authors_names         0\n",
       "genres                0\n",
       "positive_review     797\n",
       "negative_review    2002\n",
       "dtype: int64"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_board_book.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21039561",
   "metadata": {},
   "source": [
    "### 3.2.  Clean and Lemmatize Book Description <a class='anchor' id='clean_desc'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "df65e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function to clean the text\n",
    "\n",
    "def clean_function (text):\n",
    "\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    \n",
    "    # remove non-ASCII characheters\n",
    "    \n",
    "    text = \"\".join(i for i in text if  ord(i)<128)\n",
    "    \n",
    "    # change to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
    "    contractions = { \n",
    "    \"ain't\": \"am not\",\"aint\": \"am not\",\n",
    "    \"aren't\": \"are not\",\"arent\": \"are not\",\n",
    "    \"can't\": \"cannot\",\"cant\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\"cant've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\"couldve\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\"couldnt\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\"couldnt've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\"didnt\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\"doesnt\": \"does not\",\n",
    "    \"don't\": \"do not\",\"dont\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\"hadnt\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\"hadnt've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\"hasnt\": \"has not\",\n",
    "    \"haven't\": \"have not\",\"havent\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\"id\": \"i would\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'm\": \"i am\",\"im\": \"i am\",\n",
    "    \"i've\": \"i have\",\"ive\": \"i have\",\n",
    "    \"isn't\": \"is not\",\"isnt\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\"mustnt\": \"must not\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that's\": \"that is\",\"thats\": \"that is\",\n",
    "    \"there'd\": \"there had\",\n",
    "    \"there's\": \"there is\",\"theres\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\"\n",
    "    }  \n",
    "\n",
    "    text = word_tokenize(text)\n",
    "    # Replace contractions with their longer forms \n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        if word in contractions:\n",
    "            new_text.append(contractions[word])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    text = \" \".join(new_text)\n",
    "        \n",
    "    # Removing english stopwords \n",
    "    text = remove_stopwords(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "862d7ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize and stemming\n",
    "\n",
    "def preprocess(text):\n",
    "    text = word_tokenize(text)\n",
    "    result = []\n",
    "    for word in text:\n",
    "\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "        lemm = nltk.stem.WordNetLemmatizer().lemmatize(word, tag_dict.get(tag, wordnet.NOUN))\n",
    "        \n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemm = stemmer.stem(lemm)\n",
    "        result.append(stemm)\n",
    "    result = \" \".join(result)\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "daab1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's clean and lemmatize description\n",
    "\n",
    "df_board_book['clean_desc'] = df_board_book['description'].apply(clean_function)\n",
    "df_board_book['lem_clean_desc'] = df_board_book['clean_desc'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f5ad70",
   "metadata": {},
   "source": [
    "### 3.3.   Recommendation System for toddlers: based on book description <a class='anchor' id='function'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "2420539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for recommending books based on Book description. It takes book title as input:\n",
    "def recomm_title(book_title):\n",
    "\n",
    "    indx = pd.Series(df_board_book.index, index = df_board_book['title'])\n",
    "\n",
    "    #Converting the book discription into vectors\n",
    "    tfModel = TfidfVectorizer(analyzer='word', ngram_range=(1, 1), min_df = 1, stop_words='english')\n",
    "    tfidf_vector = tfModel.fit_transform(df_board_book['lem_clean_desc'])\n",
    "    \n",
    "    # Estimate the similarity of book description based on Cosine Similarity\n",
    "    similarity_matrix = cosine_similarity(tfidf_vector, tfidf_vector)\n",
    "    \n",
    "    # Get the index corresponding to original_title\n",
    "       \n",
    "    idx = indx[book_title]# Get the pairwsie similarity scores \n",
    "    similar_books = sorted(list(enumerate(similarity_matrix[idx])), key=lambda x: x[1], reverse=True)\n",
    "    Top_five_similar_books = similar_books[1:6]# Book indicies\n",
    "    book_indices = [i[0] for i in Top_five_similar_books]\n",
    "   \n",
    "    # Top 10 book recommendation\n",
    "    recommendation = df_board_book[['title', 'authors_names']].iloc[book_indices]\n",
    "       \n",
    "    # It reads the top 5 recommended book urls and print the images\n",
    "    \n",
    "\n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "f1038aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>Otters Love to Play</td>\n",
       "      <td>['Jonathan London', 'Meilo So']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>Good Night, Little Sea Otter</td>\n",
       "      <td>['Janet Halfmann', 'Wish Williams']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>Baby Otter</td>\n",
       "      <td>['Ginjer L. Clarke', 'Robbin Cuddy']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>A Lot of Otters</td>\n",
       "      <td>['Barbara Helen Berger']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>Otter Loves Halloween</td>\n",
       "      <td>['Sam Garton']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title                         authors_names\n",
       "2475           Otters Love to Play       ['Jonathan London', 'Meilo So']\n",
       "1476  Good Night, Little Sea Otter   ['Janet Halfmann', 'Wish Williams']\n",
       "1872                    Baby Otter  ['Ginjer L. Clarke', 'Robbin Cuddy']\n",
       "2326               A Lot of Otters              ['Barbara Helen Berger']\n",
       "4263         Otter Loves Halloween                        ['Sam Garton']"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomm_title('Baby Sea Otter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982549e9",
   "metadata": {},
   "source": [
    "## 5. Book Recommendation System for Teenagers based on book reviews <a class='anchor' id='reviews'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2aefdf",
   "metadata": {},
   "source": [
    "Let's find the books for kids. We will drop the toddlers' books from datafarme. We then drop the books with empty positive reviews. Then we look at the length of reviews and only keep those with words between 1000 to 5000. There are some words with so many reviews such as Harry Potter series, which will affect the topic extraction.\n",
    "\n",
    "Non- will be used to etract topics. This methods outperforms LDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ef9fb0",
   "metadata": {},
   "source": [
    "### 5.1. Find Teenage Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "6285e9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52688, 15)"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_kid_book\n",
    "non_kid_list = board_book_list \n",
    "mask = ~df['book_id'].isin(set(non_kid_list))\n",
    "df_kid_book = df[mask]\n",
    "df_kid_book = df_kid_book.reset_index()\n",
    "df_kid_book.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "df_kid_book.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "73e2af60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_id                0\n",
       "isbn                4214\n",
       "title                  0\n",
       "description            0\n",
       "num_pages              0\n",
       "authors                0\n",
       "ratings_count          0\n",
       "average_rating         0\n",
       "image_url              0\n",
       "url                    0\n",
       "similar_books          0\n",
       "authors_names          0\n",
       "genres                 0\n",
       "positive_review     9639\n",
       "negative_review    20391\n",
       "dtype: int64"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kid_book.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097c352b",
   "metadata": {},
   "source": [
    "### 5.2. Drop Books with No Positive Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "2e57bea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kid_book.dropna(subset=['positive_review'], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "f074bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's check the length of reviews\n",
    "def splitt(text):\n",
    "    text = text.split()\n",
    "    return len(text)\n",
    "\n",
    "df_kid_book['review_length'] = df_kid_book['positive_review'].apply(splitt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "10543290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_kid_book['review_length'].plot.hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "e9439009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_kid_book.loc[df_kid_book['review_length']<5000, 'review_length'].plot.hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "c8d8e7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3925, 16)"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_review_list = df_kid_book.loc[(df_kid_book['review_length']>1000) & (df_kid_book['review_length']<5000), 'book_id']\n",
    "mask = df_kid_book['book_id'].isin(long_review_list)\n",
    "df_kid_book = df_kid_book[mask]\n",
    "df_kid_book = df_kid_book.reset_index()\n",
    "df_kid_book.drop(['index'], axis=1, inplace=True)\n",
    "df_kid_book.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857c39b7",
   "metadata": {},
   "source": [
    "## 5.3. Topic Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05229f66",
   "metadata": {},
   "source": [
    "### 5.3.1.  Find Vey Common Words from Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "913757cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3176, 1)\n"
     ]
    }
   ],
   "source": [
    "tfModel = TfidfVectorizer(stop_words='english', analyzer='word', ngram_range=(1, 1), min_df = 100)\n",
    "\n",
    "data_cv = tfModel.fit_transform(df_kid_book['positive_review'])\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=tfModel.get_feature_names())\n",
    "data_dtm.index = df_kid_book.index\n",
    "data_dtm_copy = data_dtm\n",
    "word_df = pd.DataFrame(data_dtm.sum())\n",
    "word_df = word_df.sort_values(by = 0, ascending = False)\n",
    "print(word_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "9b34d28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <td>710.140758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>340.885852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>read</th>\n",
       "      <td>311.436500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>198.258121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>illustrations</th>\n",
       "      <td>181.525774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>176.194188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>169.438790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books</th>\n",
       "      <td>167.185898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>160.243634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>series</th>\n",
       "      <td>149.773173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>149.250380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>147.205859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>137.870481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun</th>\n",
       "      <td>136.345727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kids</th>\n",
       "      <td>130.985262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>120.425074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reading</th>\n",
       "      <td>116.686844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>115.069156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>110.810969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loved</th>\n",
       "      <td>109.877241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "book           710.140758\n",
       "story          340.885852\n",
       "read           311.436500\n",
       "children       198.258121\n",
       "illustrations  181.525774\n",
       "like           176.194188\n",
       "love           169.438790\n",
       "books          167.185898\n",
       "great          160.243634\n",
       "series         149.773173\n",
       "little         149.250380\n",
       "just           147.205859\n",
       "really         137.870481\n",
       "fun            136.345727\n",
       "kids           130.985262\n",
       "time           120.425074\n",
       "reading        116.686844\n",
       "family         115.069156\n",
       "good           110.810969\n",
       "loved          109.877241"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "cc79c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = []\n",
    "custom_stop_words = word_df[0:40].index \n",
    "custom_stop_words = list(custom_stop_words)\n",
    "custom_stop_words =  custom_stop_words + ['families', 'years', 'reader', 'illustration', 'picture']\n",
    "\n",
    "def custom_clean(text):\n",
    "    text = text.split()\n",
    "    stops = custom_stop_words \n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c23425",
   "metadata": {},
   "source": [
    "### 5.3.2. Clean the Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "dd43809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_kid_book['first_round'] = df_kid_book['positive_review'].apply(clean_function)\n",
    "df_kid_book['second_round'] = df_kid_book['first_round'].apply(custom_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d7c07",
   "metadata": {},
   "source": [
    "### 5.3.3. Extract Verbs from Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "ef9cfeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))        \n",
    "        \n",
    "def preprocess(text):\n",
    "    text = word_tokenize(text)\n",
    "    result = []\n",
    "    for word in text:\n",
    "\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "        lemm = nltk.stem.WordNetLemmatizer().lemmatize(word, tag_dict.get(tag, wordnet.NOUN))\n",
    "        \n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemm = stemmer.stem(lemm)\n",
    "        result.append(stemm)\n",
    "    result = \" \".join(result)\n",
    "    return result\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    return stemmer.stem(nltk.stem.WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "        \n",
    "# Let's create a function to pull out nouns from a string of text\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)\n",
    "\n",
    "def adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the  adjectives.'''\n",
    "    is_adj = lambda pos: pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    adj = [word for (word, pos) in pos_tag(tokenized) if is_adj(pos)] \n",
    "    return ' '.join(adj)\n",
    "\n",
    "def review_process(text):\n",
    "    text = word_tokenize(text)\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    result = []\n",
    "    for word in text:\n",
    "        stemm = stemmer.stem(nltk.stem.WordNetLemmatizer().lemmatize(word, pos='v'))\n",
    "        result.append(stemm)\n",
    "    result = \" \".join(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def nouns_v(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and verbs.'''\n",
    "    is_noun_v = lambda pos: pos[:2] == 'NN' or pos[:2] == 'VB'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_v = [word for (word, pos) in pos_tag(tokenized) if is_noun_v(pos)] \n",
    "    return ' '.join(nouns_v)\n",
    "\n",
    "def verbs(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the the verbs.'''\n",
    "    is_verb = lambda pos: pos[:2] == 'VB'\n",
    "    tokenized = word_tokenize(text)\n",
    "    verbs = [word for (word, pos) in pos_tag(tokenized) if is_verb(pos)] \n",
    "    return ' '.join(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "5db55bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kid_book['review_topic'] = df_kid_book['second_round'].apply(review_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "97897b34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For topic 1 the words with the highest value are:\n",
      "wants      1.091823\n",
      "gets       0.703424\n",
      "want       0.547024\n",
      "makes      0.453737\n",
      "goes       0.450247\n",
      "going      0.441441\n",
      "comes      0.422018\n",
      "loves      0.402018\n",
      "trying     0.385610\n",
      "getting    0.383251\n",
      "finds      0.347558\n",
      "takes      0.310140\n",
      "play       0.294451\n",
      "having     0.286352\n",
      "come       0.285815\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "\n",
      "For topic 2 the words with the highest value are:\n",
      "rhyming        2.161246\n",
      "rhymes         0.235384\n",
      "rhyme          0.205882\n",
      "sing           0.134738\n",
      "bed            0.124288\n",
      "illustrated    0.119661\n",
      "bright         0.116831\n",
      "makes          0.109859\n",
      "loves          0.104650\n",
      "engaging       0.089836\n",
      "received       0.086403\n",
      "got            0.084991\n",
      "enjoyed        0.084684\n",
      "sounds         0.082127\n",
      "rhymed         0.081130\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "\n",
      "For topic 3 the words with the highest value are:\n",
      "rose          1.992203\n",
      "booke         0.079514\n",
      "devoted       0.073576\n",
      "baking        0.056572\n",
      "wilder        0.048246\n",
      "talking       0.048092\n",
      "paling        0.043144\n",
      "keluarga      0.042674\n",
      "weaving       0.041019\n",
      "oscar         0.039956\n",
      "said          0.036638\n",
      "diana         0.035763\n",
      "wonderland    0.034745\n",
      "weave         0.034668\n",
      "makes         0.034251\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "\n",
      "For topic 4 the words with the highest value are:\n",
      "illustrated    0.716918\n",
      "includes       0.420238\n",
      "told           0.403190\n",
      "writing        0.385591\n",
      "amazing        0.384727\n",
      "stunning       0.381878\n",
      "fascinating    0.364303\n",
      "makes          0.349150\n",
      "based          0.348484\n",
      "look           0.338755\n",
      "written        0.331240\n",
      "inspiring      0.312018\n",
      "filled         0.291536\n",
      "gives          0.285054\n",
      "included       0.281447\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "\n",
      "For topic 5 the words with the highest value are:\n",
      "remember    0.831135\n",
      "know        0.700318\n",
      "enjoyed     0.637511\n",
      "got         0.633606\n",
      "said        0.605131\n",
      "writing     0.563506\n",
      "ending      0.561107\n",
      "going       0.559188\n",
      "liked       0.533739\n",
      "written     0.533518\n",
      "thought     0.510507\n",
      "felt        0.422940\n",
      "believe     0.386280\n",
      "took        0.364872\n",
      "started     0.360738\n",
      "Name: 4, dtype: float64\n",
      "\n",
      "\n",
      "For topic 6 the words with the highest value are:\n",
      "king         2.443603\n",
      "knight       0.165958\n",
      "retelling    0.143551\n",
      "kingdom      0.126489\n",
      "save         0.111987\n",
      "dragon       0.075154\n",
      "known        0.070531\n",
      "telling      0.065566\n",
      "know         0.064852\n",
      "kadir        0.063802\n",
      "set          0.063778\n",
      "lands        0.061739\n",
      "faces        0.060204\n",
      "won          0.059181\n",
      "told         0.058773\n",
      "Name: 5, dtype: float64\n",
      "\n",
      "\n",
      "For topic 7 the words with the highest value are:\n",
      "willems      2.434722\n",
      "piggie       0.716829\n",
      "gerald       0.500647\n",
      "elephant     0.389814\n",
      "mo           0.350267\n",
      "beginning    0.196775\n",
      "sharing      0.191452\n",
      "snake        0.187235\n",
      "ending       0.174242\n",
      "pigeon       0.168816\n",
      "friend       0.151481\n",
      "laughing     0.136135\n",
      "know         0.132009\n",
      "trying       0.125161\n",
      "laughed      0.124023\n",
      "Name: 6, dtype: float64\n",
      "\n",
      "\n",
      "For topic 8 the words with the highest value are:\n",
      "bullying    2.061201\n",
      "bullied     0.742789\n",
      "dealing     0.162856\n",
      "standing    0.160766\n",
      "stand       0.132238\n",
      "kylie       0.131516\n",
      "feel        0.120868\n",
      "mean        0.117733\n",
      "hurt        0.109530\n",
      "teased      0.107427\n",
      "helps       0.103195\n",
      "deal        0.094158\n",
      "boys        0.090059\n",
      "help        0.089828\n",
      "friend      0.086997\n",
      "Name: 7, dtype: float64\n",
      "\n",
      "\n",
      "For topic 9 the words with the highest value are:\n",
      "poems          1.912756\n",
      "poetry         0.326162\n",
      "poem           0.224795\n",
      "wonderland     0.190182\n",
      "writing        0.146009\n",
      "written        0.088341\n",
      "included       0.086516\n",
      "silverstein    0.077290\n",
      "falling        0.073154\n",
      "shel           0.072108\n",
      "includes       0.068768\n",
      "accompanied    0.068214\n",
      "wrote          0.064628\n",
      "enjoyed        0.063723\n",
      "makes          0.062702\n",
      "Name: 8, dtype: float64\n",
      "\n",
      "\n",
      "For topic 10 the words with the highest value are:\n",
      "mccombie      0.789185\n",
      "felt          0.736687\n",
      "rowan         0.525410\n",
      "rude          0.446925\n",
      "adored        0.437552\n",
      "wrote         0.407025\n",
      "adopted       0.271097\n",
      "introduced    0.267997\n",
      "kyra          0.263062\n",
      "linn          0.263062\n",
      "misshapen     0.263062\n",
      "living        0.253597\n",
      "partaking     0.252503\n",
      "sobs          0.249187\n",
      "downs         0.248904\n",
      "Name: 9, dtype: float64\n",
      "\n",
      "\n",
      "For topic 11 the words with the highest value are:\n",
      "lost            2.180499\n",
      "missing         0.367611\n",
      "loses           0.280736\n",
      "ending          0.245125\n",
      "left            0.234652\n",
      "finds           0.224635\n",
      "named           0.209365\n",
      "gets            0.208026\n",
      "finding         0.194030\n",
      "heartwarming    0.181803\n",
      "died            0.174030\n",
      "gone            0.172574\n",
      "moving          0.167971\n",
      "beloved         0.164726\n",
      "friend          0.145807\n",
      "Name: 10, dtype: float64\n",
      "\n",
      "\n",
      "For topic 12 the words with the highest value are:\n",
      "received     1.390714\n",
      "learning     0.662333\n",
      "lived        0.502869\n",
      "learn        0.499960\n",
      "provided     0.414321\n",
      "written      0.359095\n",
      "learned      0.304815\n",
      "enjoyed      0.279821\n",
      "expressed    0.269505\n",
      "given        0.257629\n",
      "teaching     0.248703\n",
      "recommend    0.234001\n",
      "captain      0.231747\n",
      "know         0.212339\n",
      "help         0.206734\n",
      "Name: 11, dtype: float64\n",
      "\n",
      "\n",
      "For topic 13 the words with the highest value are:\n",
      "snow         1.522146\n",
      "waiting      0.140487\n",
      "retelling    0.132865\n",
      "snowflake    0.114930\n",
      "fractured    0.109035\n",
      "sleeping     0.099994\n",
      "christmas    0.080930\n",
      "seen         0.079929\n",
      "toys         0.078731\n",
      "falling      0.077839\n",
      "fairy        0.076269\n",
      "grimm        0.073285\n",
      "red          0.066409\n",
      "looking      0.066031\n",
      "look         0.065106\n",
      "Name: 12, dtype: float64\n",
      "\n",
      "\n",
      "For topic 14 the words with the highest value are:\n",
      "bear           1.735530\n",
      "bed            0.379234\n",
      "sleeping       0.272501\n",
      "cave           0.246781\n",
      "bears          0.178296\n",
      "sleep          0.158617\n",
      "awake          0.127920\n",
      "wants          0.127577\n",
      "leaves         0.122473\n",
      "hibernating    0.116051\n",
      "tired          0.111524\n",
      "said           0.108001\n",
      "soothing       0.105424\n",
      "sharing        0.103986\n",
      "mouse          0.095485\n",
      "Name: 13, dtype: float64\n",
      "\n",
      "\n",
      "For topic 15 the words with the highest value are:\n",
      "counting      1.459030\n",
      "count         0.174387\n",
      "bed           0.110125\n",
      "page          0.078596\n",
      "math          0.071806\n",
      "lemonade      0.067982\n",
      "dancing       0.066533\n",
      "primates      0.064227\n",
      "stack         0.058730\n",
      "endangered    0.058304\n",
      "cut           0.058087\n",
      "counts        0.056400\n",
      "playing       0.046966\n",
      "lap           0.045159\n",
      "senor         0.045155\n",
      "Name: 14, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_verbs = pd.DataFrame(df_kid_book['second_round'].apply(verbs))\n",
    "\n",
    "tv_verb = TfidfVectorizer(ngram_range = (1,1), min_df = 1)\n",
    "data_tv_verb = tv_verb.fit_transform(data_verbs['second_round'])\n",
    "\n",
    "nmf_model = NMF(15)\n",
    "doc_topic = nmf_model.fit_transform(data_tv_verb)\n",
    "\n",
    "components_df = pd.DataFrame(nmf_model.components_, columns=tv_verb.get_feature_names())\n",
    "\n",
    "for topic in range(components_df.shape[0]):\n",
    "    tmp = components_df.iloc[topic]\n",
    "    print(f'For topic {topic+1} the words with the highest value are:')\n",
    "    print(tmp.nlargest(15))\n",
    "    print('\\n')\n",
    "                                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "c95275ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topics = pd.DataFrame(doc_topic, index = df_kid_book.index)\n",
    "doc_topics['topic_number'] = doc_topics.idxmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35a942a",
   "metadata": {},
   "source": [
    "### 5.4. Give Topics Labels and Classify Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "2b332895",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1: planning', '2: rhyming_and_singing', '3: love_and_family', '4: inspirational', '5: memories', '6: history', \n",
    "          '7: animals', '8: bullying', '9: poetry', '10: fiction ', '11: missing_loved_ones', '12: teaching',\n",
    "          '13: Christmas_tories', '14: animals_and_nature' ,'15: teach_maths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "id": "f98fa8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_dic = {}\n",
    "for i in range(len(labels)):\n",
    "    topics_dic[i] = labels[i]\n",
    "for i in range(len(doc_topics)):\n",
    "    x = doc_topics.loc[i, 'topic_number']\n",
    "    doc_topics.loc[i, 'label'] = topics_dic[x]\n",
    "topics_book = doc_topics['label']\n",
    "kid_books = df_kid_book.merge(topics_book, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "e151480c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>authors</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>image_url</th>\n",
       "      <th>url</th>\n",
       "      <th>similar_books</th>\n",
       "      <th>authors_names</th>\n",
       "      <th>genres</th>\n",
       "      <th>positive_review</th>\n",
       "      <th>negative_review</th>\n",
       "      <th>review_length</th>\n",
       "      <th>first_round</th>\n",
       "      <th>second_round</th>\n",
       "      <th>review_topic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076040</td>\n",
       "      <td>069001287X</td>\n",
       "      <td>Anno's Counting Book</td>\n",
       "      <td>Every child is a natural mathematician, accord...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>[{'author_id': '72077', 'role': ''}]</td>\n",
       "      <td>551.0</td>\n",
       "      <td>4.06</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "      <td>https://www.goodreads.com/book/show/1076040.An...</td>\n",
       "      <td>['289881', '6516912', '1873420', '282631', '21...</td>\n",
       "      <td>['Mitsumasa Anno']</td>\n",
       "      <td>{'children': 96, 'non-fiction': 6, 'fiction': 4}</td>\n",
       "      <td>Genre: Counting \\n Summary: A wordless picture...</td>\n",
       "      <td>Awesome description and intro. to math for you...</td>\n",
       "      <td>1368</td>\n",
       "      <td>genre counting summary wordless picture book d...</td>\n",
       "      <td>genre counting summary wordless depicts notion...</td>\n",
       "      <td>genr count summari wordless depict notion coun...</td>\n",
       "      <td>15: teach_maths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>34740357</td>\n",
       "      <td>0802854923</td>\n",
       "      <td>Plume</td>\n",
       "      <td>In this lovely book, young readers are introdu...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>[{'author_id': '13832085', 'role': ''}]</td>\n",
       "      <td>123.0</td>\n",
       "      <td>4.17</td>\n",
       "      <td>https://images.gr-assets.com/books/1494501837m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/34740357-p...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Isabelle Simler']</td>\n",
       "      <td>{'children': 31, 'fiction': 1, 'non-fiction': 1}</td>\n",
       "      <td>ADORABLE. As a proud owner of a mini black pan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1466</td>\n",
       "      <td>adorable proud owner mini black panther enjoys...</td>\n",
       "      <td>adorable proud owner mini black panther enjoys...</td>\n",
       "      <td>ador proud owner mini black panther enjoy feat...</td>\n",
       "      <td>15: teach_maths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>16056793</td>\n",
       "      <td>0745964141</td>\n",
       "      <td>My Very First Noah's Ark Playtime: Activity Bo...</td>\n",
       "      <td>An activity book with stickers to keep childre...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>[{'author_id': '177078', 'role': ''}, {'author...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.44</td>\n",
       "      <td>https://images.gr-assets.com/books/1349813698m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/16056793-m...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Lois Rock', 'Alex Ayliffe']</td>\n",
       "      <td>{'children': 4}</td>\n",
       "      <td>My Very First Noah's Ark Playtime is the third...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1190</td>\n",
       "      <td>noah s ark playtime sticker book line ve enjoy...</td>\n",
       "      <td>noah s ark playtime sticker line ve enjoyed op...</td>\n",
       "      <td>noah s ark playtim sticker line ve enjoy opini...</td>\n",
       "      <td>15: teach_maths</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id        isbn                                              title  \\\n",
       "3     1076040  069001287X                               Anno's Counting Book   \n",
       "65   34740357  0802854923                                              Plume   \n",
       "262  16056793  0745964141  My Very First Noah's Ark Playtime: Activity Bo...   \n",
       "\n",
       "                                           description  num_pages  \\\n",
       "3    Every child is a natural mathematician, accord...       28.0   \n",
       "65   In this lovely book, young readers are introdu...       42.0   \n",
       "262  An activity book with stickers to keep childre...       16.0   \n",
       "\n",
       "                                               authors  ratings_count  \\\n",
       "3                 [{'author_id': '72077', 'role': ''}]          551.0   \n",
       "65             [{'author_id': '13832085', 'role': ''}]          123.0   \n",
       "262  [{'author_id': '177078', 'role': ''}, {'author...           18.0   \n",
       "\n",
       "     average_rating                                          image_url  \\\n",
       "3              4.06  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
       "65             4.17  https://images.gr-assets.com/books/1494501837m...   \n",
       "262            4.44  https://images.gr-assets.com/books/1349813698m...   \n",
       "\n",
       "                                                   url  \\\n",
       "3    https://www.goodreads.com/book/show/1076040.An...   \n",
       "65   https://www.goodreads.com/book/show/34740357-p...   \n",
       "262  https://www.goodreads.com/book/show/16056793-m...   \n",
       "\n",
       "                                         similar_books  \\\n",
       "3    ['289881', '6516912', '1873420', '282631', '21...   \n",
       "65                                                  []   \n",
       "262                                                 []   \n",
       "\n",
       "                     authors_names  \\\n",
       "3               ['Mitsumasa Anno']   \n",
       "65             ['Isabelle Simler']   \n",
       "262  ['Lois Rock', 'Alex Ayliffe']   \n",
       "\n",
       "                                               genres  \\\n",
       "3    {'children': 96, 'non-fiction': 6, 'fiction': 4}   \n",
       "65   {'children': 31, 'fiction': 1, 'non-fiction': 1}   \n",
       "262                                   {'children': 4}   \n",
       "\n",
       "                                       positive_review  \\\n",
       "3    Genre: Counting \\n Summary: A wordless picture...   \n",
       "65   ADORABLE. As a proud owner of a mini black pan...   \n",
       "262  My Very First Noah's Ark Playtime is the third...   \n",
       "\n",
       "                                       negative_review  review_length  \\\n",
       "3    Awesome description and intro. to math for you...           1368   \n",
       "65                                                 NaN           1466   \n",
       "262                                                NaN           1190   \n",
       "\n",
       "                                           first_round  \\\n",
       "3    genre counting summary wordless picture book d...   \n",
       "65   adorable proud owner mini black panther enjoys...   \n",
       "262  noah s ark playtime sticker book line ve enjoy...   \n",
       "\n",
       "                                          second_round  \\\n",
       "3    genre counting summary wordless depicts notion...   \n",
       "65   adorable proud owner mini black panther enjoys...   \n",
       "262  noah s ark playtime sticker line ve enjoyed op...   \n",
       "\n",
       "                                          review_topic            label  \n",
       "3    genr count summari wordless depict notion coun...  15: teach_maths  \n",
       "65   ador proud owner mini black panther enjoy feat...  15: teach_maths  \n",
       "262  noah s ark playtim sticker line ve enjoy opini...  15: teach_maths  "
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kid_books.loc[kid_books['label']=='15: teach_maths'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "id": "7cf7ea8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>authors</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>image_url</th>\n",
       "      <th>url</th>\n",
       "      <th>similar_books</th>\n",
       "      <th>authors_names</th>\n",
       "      <th>genres</th>\n",
       "      <th>positive_review</th>\n",
       "      <th>negative_review</th>\n",
       "      <th>review_length</th>\n",
       "      <th>first_round</th>\n",
       "      <th>second_round</th>\n",
       "      <th>review_topic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>12394114</td>\n",
       "      <td>0062081950</td>\n",
       "      <td>Penny and Her Song</td>\n",
       "      <td>When Penny comes home from school, she is read...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>[{'author_id': '193', 'role': ''}]</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>https://images.gr-assets.com/books/1325397916m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/12394114-p...</td>\n",
       "      <td>['12909138', '12177920', '11867718', '11737017...</td>\n",
       "      <td>['Kevin Henkes']</td>\n",
       "      <td>{'children': 116, 'fiction': 18, 'fantasy, par...</td>\n",
       "      <td>http://librarianosnark.blogspot.com/2...,Be pr...</td>\n",
       "      <td>Penny has a special song she wants to sing to ...</td>\n",
       "      <td>1607</td>\n",
       "      <td>young children delight kevin henkes book begin...</td>\n",
       "      <td>delight kevin henkes beginning relate penny wa...</td>\n",
       "      <td>delight kevin henk begin relat penni want pare...</td>\n",
       "      <td>14: animals_and_nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>9327107</td>\n",
       "      <td>0763650552</td>\n",
       "      <td>Tell Me the Day Backwards</td>\n",
       "      <td>In this delightful bedtime story, a young bear...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[{'author_id': '895230', 'role': ''}, {'author...</td>\n",
       "      <td>482.0</td>\n",
       "      <td>3.83</td>\n",
       "      <td>https://images.gr-assets.com/books/1320561969m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/9327107-te...</td>\n",
       "      <td>['10427002', '8739824', '11532312', '10326007'...</td>\n",
       "      <td>['Albert Lamb', 'David McPhail']</td>\n",
       "      <td>{'children': 64, 'fiction': 7}</td>\n",
       "      <td>Tell Me the Day Backwards by Albert Lamb is is...</td>\n",
       "      <td>A baby bear is encouraged by his mother to rem...</td>\n",
       "      <td>1422</td>\n",
       "      <td>tell day backwards albert lamb young bear cub ...</td>\n",
       "      <td>tell day backwards albert lamb bear cub gettin...</td>\n",
       "      <td>tell day backward albert lamb bear cub get rea...</td>\n",
       "      <td>14: animals_and_nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>233714</td>\n",
       "      <td>0140309578</td>\n",
       "      <td>Pippi Longstocking</td>\n",
       "      <td>The beloved story of a spunky young girl and h...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>[{'author_id': '410653', 'role': ''}, {'author...</td>\n",
       "      <td>786.0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>https://images.gr-assets.com/books/1309287432m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/233714.Pip...</td>\n",
       "      <td>['1306827', '1148052', '224538', '157551', '46...</td>\n",
       "      <td>['Astrid Lindgren', 'Louis S. Glanzman', 'Flor...</td>\n",
       "      <td>{'children': 4702, 'fiction': 923, 'young-adul...</td>\n",
       "      <td>A rather odd combination of circumstances have...</td>\n",
       "      <td>Clearly I don't understand the magic of Pippi ...</td>\n",
       "      <td>1369</td>\n",
       "      <td>odd combination circumstances led read book ha...</td>\n",
       "      <td>odd combination circumstances led hand appears...</td>\n",
       "      <td>odd combin circumst lead hand appear norwegian...</td>\n",
       "      <td>14: animals_and_nature</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id        isbn                      title  \\\n",
       "113  12394114  0062081950         Penny and Her Song   \n",
       "127   9327107  0763650552  Tell Me the Day Backwards   \n",
       "164    233714  0140309578         Pippi Longstocking   \n",
       "\n",
       "                                           description  num_pages  \\\n",
       "113  When Penny comes home from school, she is read...       32.0   \n",
       "127  In this delightful bedtime story, a young bear...       40.0   \n",
       "164  The beloved story of a spunky young girl and h...      160.0   \n",
       "\n",
       "                                               authors  ratings_count  \\\n",
       "113                 [{'author_id': '193', 'role': ''}]         1119.0   \n",
       "127  [{'author_id': '895230', 'role': ''}, {'author...          482.0   \n",
       "164  [{'author_id': '410653', 'role': ''}, {'author...          786.0   \n",
       "\n",
       "     average_rating                                          image_url  \\\n",
       "113            3.80  https://images.gr-assets.com/books/1325397916m...   \n",
       "127            3.83  https://images.gr-assets.com/books/1320561969m...   \n",
       "164            4.11  https://images.gr-assets.com/books/1309287432m...   \n",
       "\n",
       "                                                   url  \\\n",
       "113  https://www.goodreads.com/book/show/12394114-p...   \n",
       "127  https://www.goodreads.com/book/show/9327107-te...   \n",
       "164  https://www.goodreads.com/book/show/233714.Pip...   \n",
       "\n",
       "                                         similar_books  \\\n",
       "113  ['12909138', '12177920', '11867718', '11737017...   \n",
       "127  ['10427002', '8739824', '11532312', '10326007'...   \n",
       "164  ['1306827', '1148052', '224538', '157551', '46...   \n",
       "\n",
       "                                         authors_names  \\\n",
       "113                                   ['Kevin Henkes']   \n",
       "127                   ['Albert Lamb', 'David McPhail']   \n",
       "164  ['Astrid Lindgren', 'Louis S. Glanzman', 'Flor...   \n",
       "\n",
       "                                                genres  \\\n",
       "113  {'children': 116, 'fiction': 18, 'fantasy, par...   \n",
       "127                     {'children': 64, 'fiction': 7}   \n",
       "164  {'children': 4702, 'fiction': 923, 'young-adul...   \n",
       "\n",
       "                                       positive_review  \\\n",
       "113  http://librarianosnark.blogspot.com/2...,Be pr...   \n",
       "127  Tell Me the Day Backwards by Albert Lamb is is...   \n",
       "164  A rather odd combination of circumstances have...   \n",
       "\n",
       "                                       negative_review  review_length  \\\n",
       "113  Penny has a special song she wants to sing to ...           1607   \n",
       "127  A baby bear is encouraged by his mother to rem...           1422   \n",
       "164  Clearly I don't understand the magic of Pippi ...           1369   \n",
       "\n",
       "                                           first_round  \\\n",
       "113  young children delight kevin henkes book begin...   \n",
       "127  tell day backwards albert lamb young bear cub ...   \n",
       "164  odd combination circumstances led read book ha...   \n",
       "\n",
       "                                          second_round  \\\n",
       "113  delight kevin henkes beginning relate penny wa...   \n",
       "127  tell day backwards albert lamb bear cub gettin...   \n",
       "164  odd combination circumstances led hand appears...   \n",
       "\n",
       "                                          review_topic                   label  \n",
       "113  delight kevin henk begin relat penni want pare...  14: animals_and_nature  \n",
       "127  tell day backward albert lamb bear cub get rea...  14: animals_and_nature  \n",
       "164  odd combin circumst lead hand appear norwegian...  14: animals_and_nature  "
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kid_books.loc[kid_books['label']=='14: animals_and_nature'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f66e715",
   "metadata": {},
   "source": [
    "## Summary <a class='anchor' id='summary'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65865363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "2b7b1880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For topic 1 the words with the highest value are:\n",
      "read        2.832094\n",
      "reading     2.488760\n",
      "charming    0.574067\n",
      "enjoy       0.390697\n",
      "ages        0.388909\n",
      "writing     0.341982\n",
      "exciting    0.331890\n",
      "child       0.309774\n",
      "fun         0.285354\n",
      "learning    0.279623\n",
      "says        0.264196\n",
      "starred     0.253085\n",
      "won         0.245602\n",
      "uses        0.243078\n",
      "includes    0.231399\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "\n",
      "For topic 2 the words with the highest value are:\n",
      "wants        1.892822\n",
      "want         0.247765\n",
      "play         0.224065\n",
      "friend       0.121499\n",
      "playing      0.097472\n",
      "won          0.095287\n",
      "discovers    0.090067\n",
      "loves        0.088348\n",
      "trying       0.083941\n",
      "looks        0.079470\n",
      "decides      0.078849\n",
      "sleep        0.077637\n",
      "says         0.077280\n",
      "arrives      0.070360\n",
      "let          0.065604\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "\n",
      "For topic 3 the words with the highest value are:\n",
      "going         1.903294\n",
      "getting       0.232672\n",
      "said          0.159028\n",
      "end           0.156003\n",
      "got           0.144125\n",
      "run           0.118044\n",
      "save          0.116757\n",
      "looks         0.076382\n",
      "says          0.074101\n",
      "win           0.073988\n",
      "believe       0.069715\n",
      "harold        0.069369\n",
      "running       0.069308\n",
      "thinking      0.068742\n",
      "determined    0.066033\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "\n",
      "For topic 4 the words with the highest value are:\n",
      "love            1.832448\n",
      "came            0.164411\n",
      "loves           0.110907\n",
      "published       0.107706\n",
      "loving          0.091487\n",
      "heartwarming    0.078353\n",
      "enjoyed         0.078212\n",
      "got             0.072975\n",
      "acclaimed       0.072450\n",
      "written         0.067676\n",
      "leave           0.067670\n",
      "born            0.065463\n",
      "tell            0.064963\n",
      "charming        0.064278\n",
      "featuring       0.063562\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "\n",
      "For topic 5 the words with the highest value are:\n",
      "lost        1.517642\n",
      "finds       0.848098\n",
      "set         0.182670\n",
      "grows       0.170569\n",
      "save        0.124772\n",
      "trying      0.112126\n",
      "missing     0.099495\n",
      "coming      0.098934\n",
      "realizes    0.098924\n",
      "left        0.091379\n",
      "follow      0.085224\n",
      "gone        0.080335\n",
      "rose        0.078505\n",
      "dog         0.077356\n",
      "miss        0.075047\n",
      "Name: 4, dtype: float64\n",
      "\n",
      "\n",
      "For topic 6 the words with the highest value are:\n",
      "know       1.629867\n",
      "need       0.566177\n",
      "want       0.171887\n",
      "save       0.157821\n",
      "start      0.124040\n",
      "won        0.121652\n",
      "turn       0.111633\n",
      "tell       0.105726\n",
      "got        0.098957\n",
      "trying     0.096123\n",
      "wanted     0.090620\n",
      "ll         0.089826\n",
      "working    0.088969\n",
      "believe    0.085678\n",
      "left       0.082242\n",
      "Name: 5, dtype: float64\n",
      "\n",
      "\n",
      "For topic 7 the words with the highest value are:\n",
      "goes        1.044116\n",
      "makes       0.805028\n",
      "takes       0.689061\n",
      "missing     0.286683\n",
      "learn       0.173042\n",
      "exciting    0.135147\n",
      "begins      0.115607\n",
      "says        0.114865\n",
      "brave       0.100363\n",
      "brings      0.099898\n",
      "engaging    0.094665\n",
      "follows     0.090366\n",
      "making      0.083571\n",
      "fun         0.081494\n",
      "learning    0.077835\n",
      "Name: 6, dtype: float64\n",
      "\n",
      "\n",
      "For topic 8 the words with the highest value are:\n",
      "comes          1.766743\n",
      "realize        0.179789\n",
      "bestselling    0.158345\n",
      "taking         0.122764\n",
      "helps          0.117668\n",
      "making         0.088899\n",
      "living         0.081834\n",
      "knows          0.078355\n",
      "begin          0.077055\n",
      "tell           0.076562\n",
      "sing           0.075904\n",
      "locked         0.073908\n",
      "turns          0.072332\n",
      "told           0.066919\n",
      "writing        0.066544\n",
      "Name: 7, dtype: float64\n",
      "\n",
      "\n",
      "For topic 9 the words with the highest value are:\n",
      "king          2.237503\n",
      "begins        0.226685\n",
      "brought       0.210873\n",
      "rose          0.185747\n",
      "banished      0.146544\n",
      "called        0.145818\n",
      "evil          0.137610\n",
      "seen          0.129127\n",
      "built         0.127629\n",
      "set           0.109753\n",
      "filled        0.108981\n",
      "knight        0.105440\n",
      "determined    0.101248\n",
      "causes        0.094539\n",
      "wicked        0.092835\n",
      "Name: 8, dtype: float64\n",
      "\n",
      "\n",
      "For topic 10 the words with the highest value are:\n",
      "winning        1.503614\n",
      "illustrated    0.795607\n",
      "lived          0.292761\n",
      "bestselling    0.237670\n",
      "written        0.237586\n",
      "acclaimed      0.186474\n",
      "told           0.176097\n",
      "fun            0.164667\n",
      "stunning       0.154851\n",
      "wore           0.153663\n",
      "exciting       0.144649\n",
      "created        0.140210\n",
      "based          0.125359\n",
      "won            0.123790\n",
      "ages           0.120753\n",
      "Name: 9, dtype: float64\n",
      "\n",
      "\n",
      "For topic 11 the words with the highest value are:\n",
      "think       1.537425\n",
      "knows       0.637950\n",
      "says        0.151296\n",
      "charming    0.138805\n",
      "looking     0.129469\n",
      "start       0.125416\n",
      "aren        0.122958\n",
      "starts      0.122224\n",
      "believe     0.121313\n",
      "look        0.106437\n",
      "written     0.099670\n",
      "happened    0.098914\n",
      "loves       0.098307\n",
      "happens     0.094539\n",
      "eating      0.085363\n",
      "Name: 10, dtype: float64\n",
      "\n",
      "\n",
      "For topic 12 the words with the highest value are:\n",
      "named         1.293947\n",
      "lives         0.973731\n",
      "beloved       0.790015\n",
      "including     0.272200\n",
      "lived         0.270304\n",
      "published     0.269435\n",
      "called        0.246291\n",
      "save          0.216854\n",
      "got           0.195247\n",
      "learns        0.189541\n",
      "acclaimed     0.185823\n",
      "determined    0.182844\n",
      "looking       0.179728\n",
      "haunting      0.167905\n",
      "given         0.153434\n",
      "Name: 11, dtype: float64\n",
      "\n",
      "\n",
      "For topic 13 the words with the highest value are:\n",
      "piggie        1.400907\n",
      "smiling       1.121751\n",
      "determined    0.306484\n",
      "play          0.154030\n",
      "wait          0.127414\n",
      "gerald        0.101667\n",
      "waiting       0.093119\n",
      "worried       0.089513\n",
      "leave         0.085242\n",
      "friends       0.081688\n",
      "fly           0.078123\n",
      "want          0.073605\n",
      "listen        0.073306\n",
      "teach         0.071434\n",
      "head          0.070515\n",
      "Name: 12, dtype: float64\n",
      "\n",
      "\n",
      "For topic 14 the words with the highest value are:\n",
      "come         1.454645\n",
      "begins       0.333443\n",
      "captain      0.143774\n",
      "moving       0.130160\n",
      "created      0.127322\n",
      "told         0.125366\n",
      "following    0.118070\n",
      "dreams       0.105315\n",
      "begin        0.094326\n",
      "including    0.092085\n",
      "leave        0.085144\n",
      "fly          0.083704\n",
      "came         0.074676\n",
      "charming     0.073851\n",
      "flying       0.073249\n",
      "Name: 13, dtype: float64\n",
      "\n",
      "\n",
      "For topic 15 the words with the highest value are:\n",
      "gets       1.322844\n",
      "help       0.979733\n",
      "filled     0.150785\n",
      "making     0.127096\n",
      "having     0.126234\n",
      "need       0.113023\n",
      "learn      0.106705\n",
      "starts     0.105785\n",
      "bring      0.094907\n",
      "turns      0.089889\n",
      "excited    0.085285\n",
      "red        0.081302\n",
      "says       0.080271\n",
      "tries      0.072321\n",
      "turn       0.071817\n",
      "Name: 14, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dff = df_kid_book\n",
    "\n",
    "dff['desc_clean'] = dff['description'].apply(clean_function)\n",
    "\n",
    "data_verbs_2 = pd.DataFrame(dff['desc_clean'].apply(verbs))\n",
    "\n",
    "tv_verb_2 = TfidfVectorizer(ngram_range = (1,1), min_df = 1)\n",
    "data_tv_verb_2 = tv_verb_2.fit_transform(data_verbs_2['desc_clean'])\n",
    "\n",
    "nmf_model_2 = NMF(15)\n",
    "doc_topic_2 = nmf_model_2.fit_transform(data_tv_verb_2)\n",
    "\n",
    "components_dff = pd.DataFrame(nmf_model_2.components_, columns=tv_verb_2.get_feature_names())\n",
    "\n",
    "for topic in range(components_dff.shape[0]):\n",
    "    tmp = components_dff.iloc[topic]\n",
    "    print(f'For topic {topic+1} the words with the highest value are:')\n",
    "    print(tmp.nlargest(15))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28bb4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_verbs_2 = pd.DataFrame(df_kid_book['second_round'].apply(verbs))\n",
    "\n",
    "tv_verb = TfidfVectorizer(ngram_range = (1,1), min_df = 1)\n",
    "data_tv_verb = tv_verb.fit_transform(data_verbs['second_round'])\n",
    "\n",
    "nmf_model = NMF(15)\n",
    "doc_topic = nmf_model.fit_transform(data_tv_verb)\n",
    "\n",
    "components_df = pd.DataFrame(nmf_model.components_, columns=tv_verb.get_feature_names())\n",
    "\n",
    "for topic in range(components_df.shape[0]):\n",
    "    tmp = components_df.iloc[topic]\n",
    "    print(f'For topic {topic+1} the words with the highest value are:')\n",
    "    print(tmp.nlargest(15))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b151a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad74f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c433b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
